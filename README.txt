Readme file for the PMMMSA-Mini-project repository

Aalborg University - Department of Electronic Systems
VGIS9 Platforms and Methods for Multi-Modal System Architectures Mini-project

Introduction :

Humans recognize facial expression without effort and delay. The challenge is to obtain a reliable facial expression recognition by machine. This is a relevant component of Human-Machine Interaction but this can be also used in a vast number of applications mostly through security, but also in psychology and medical fields, or even in artistic ways. The aim of this mini-project is to combine facial expression recognition and sound processing in order to have on influence on the user's input sounds based on his/her facial features' movements. 

Modalities involved :

- Video-based facial expression recognition (using OpenCV framework)
- Sound processing (using Pure Data framework)

Communication between these 2 block will be achieved using OSC (Open Sound Control)

Content of the project :

This project can be viewed as a "game", structured in 3 main steps :
- First step is input sound recording, where the user has to make several sound samples, for example by pronouncing vowels;
- Second step is about facial expression recognition, where the main facial features (i.e : eyes, lips) will be extracted, and their movement paired with sound processing (i.e : frequency and volume variations) ;
- Last step is the resulting output, which can be described as interactive music.

Group members :
Maxime Coupez
Kim-Adeline Miguel
Julia Alexandra Vigo